---
title: 'Data Wrangling: stringr and forcats'
author: "Dzaky Jaya"
date: "2022-09-04"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
load("./strings/strings.RData")
```

# String Matching

## str_detect()

detect a pattern match inside given string.\
similar to base R `grepl`\
in some circumstance this function would seems similar to `like` clause in SQL\

```{r}
df <- ggplot2::mpg

df %>% filter(trans %like% "auto") # retrieve all records with automatic transmissions
# we can use str_detect to get same results
df %>% filter(str_detect(trans, "auto"))
```

```{r}
fruit[str_detect(fruit, "a")]
# this way is similar to:
fruit[grepl("a", fruit)]

# get all fruit no contain letter "a"
fruit[str_detect(fruit, "a", negate = T)]

data.frame(fruit) %>% filter(str_detect(fruit, "a"))
```

## str_which()

locate the indexes of strings, which contain a pattern match\
similar to base R `grep`

```{r}
str_which(c("abcd", "pqrsa"), "a")
```

## str_count()

count the number of pattern matches in given strings.

```{r}
data.frame(fruit) %>% filter(str_count(fruit, "a") >= 2)
```

## str_locate() and str_locate_all()

locate the position(s) of pattern match(es) in given string.\
`str_locate`: position of the first match\
`str_locate_all`: position of all matches

```{r}
fruit.df %>% mutate(start= str_locate(fruit, pattern = "bl")[,"start"],
                    end = str_locate(fruit, pattern = "bl")[,"end"])
```

```{r}
str_locate_all(fruit, "bla")
```

# String Subsetting

## str_sub()

similar to base R `substr()`\
extract part part of a string from a character vector

```{r}
str_sub(fruit, 1, 4) %>% tibble()

words %>% str_sub(1, 1) %>% tibble()
```

## str_subset()

return only the strings that contain pattern match

```{r}
str_subset(fruit, "bla")
```

## str_extract() & str_extract_all()

return the first (or every) pattern match as a vector

```{r}
str_extract(fruit, "app") %>% tibble()
```

```{r}
str_extract_all(fruit, "ap") %>% tibble
```

## str_match() & str_match_all()

return the first (or every) pattern match found in each string, as a matrix for each group in pattern.

```{r}
str_match(fruit, "a") %>% tibble()
```

# String Length

## str_length()

return the width of the character string.

```{r}
fruit %>% str_length()

# subsetting
fruit[fruit %>% str_length()>10]
```

## str_pad()

to get string with equal length

```{r}
fruit %>% str_pad(width = 10, pad = "F", side = "left")
```

## str_trunc

truncate the width of string\
almost similar to opposite of `str_pad`

```{r}
fruit %>% str_trunc(width = 7, side = "left", ellipsis = "fruit")

# if the width more than ellipsis
fruit %>% str_trunc(width = 6, side = "left", ellipsis = "fruit ")
```

in str_trunc, if width shouldn't less than ellipsis,\
when the width and the ellipsis are equal, they will not be truncated, instead the ellipsis will mutated to the string

## str_trim

trim whitespaces from start and/or end of the string\

```{r}
# str_trim(fruit, side = "both" )
```

# String Mutating

## str_sub()

form:\
`str_sub(string, star, end) < replacement`

```{r}
fruitexp <- fruit
str_sub(fruitexp, 0, 0) <- "FRUIT "
fruitexp %>% head(10)
```

## str_replace() & str_repalce_all

replace the first matched pattern in each string\
form:\
`str_replace(string, pattern, replacement)`\
\
str_replace_all will applied to all matched pattern

```{r}
str_replace(fruit, "^a", "A")
str_replace(fruit, "a", "A")

str_replace_all(fruit, "a", "A")
```

## str_to_lower/\_upper/\_tittle()

convert strings to lower/upper/title case\

```{r}
sentences.df$sentence <- str_to_upper(sentences.df$sentence)

sentences.df <- sentences.df %>% mutate(sentence = str_to_lower(sentence))

sentences.df$sentence <- str_to_title(sentences.df$sentence)
```

# joining and splitting strings

## str_c()

joining multiple strings into a single string

```{r}
exp <- fruit.df %>% mutate(`3 ahead` = str_sub(fruit.df$fruit, 1,3))

exp %>% mutate(`full name` = str_c("fruit", exp$fruit, sep = " "))


exp %>% mutate(`full name` = case_when(
        str_detect(exp$fruit, "^[ab]") ~ str_c("buah a/b", exp$fruit, sep = " "),
        T ~ str_c("buah selain a/b", exp$fruit, sep = " ")
))
```

## str_dup()

repeat a astring multiple times

```{r}
exp %>% mutate(`string duplicate` = str_dup(exp$`3 ahead`, 3))
```

## str_split_fixed / str_split

split a vector of string into matrix of substrings (str_split - returns a list of substrings)

```{r}
str_split_fixed(sentences.df$sentence, " ", 2) %>% tibble
```

## str_glue()

merge together strings and {expressions}

```{r}
str_glue("the {fruit[31]} result of 2 times 10 is {2*10}")

fruit.df %>% mutate(details = str_glue("{fruit.df$fruit} is either sweet or not"))

fruit.df %>% mutate(details = case_when(
        str_detect(fruit, "^[abc]") ~ str_glue("{fruit.df$fruit} is sweet"),
        T ~ str_glue("{fruit.df$fruit} is BAD"))) %>% tail()
```

## str_glue_data

use a data.frame, list or environment to create string from strings and {expressions}

```{r}
str_glue_data(exp, "the fruit is {fruit} and the third first character is {`3 ahead`}") %>% tibble()
```

# string heper function

## str_order()

return a vector of indexes after character vector is sorted

```{r}
str_order(sentences) %>% tibble()

# use subsetting to ordering value instead of indexes
sentences[str_order(sentences)] %>% tibble()
```

## str_sort()

return sorted value

```{r}
str_sort(sentences) %>% tibble()
```

## str_view() & str_view_all

an html rendering function

```{r}
# install.packages("htmlwidgets")
library(htmlwidgets)

str_view("aku mau makan", "a")

str_view_all("aku mau makan", "a")
```

# Factors (forcats)

## fct_count()

count the number of value for each level

```{r}
dt <- mpg %>% mutate_at(.vars = c("manufacturer", "model", "trans", "class"), .funs = as.factor)

fct_count(dt$manufacturer)

dt %>% .$manufacturer %>% fct_count()
```

## fct_unique

similar to base R `levels()`\
return the unique values, removing duplicates

```{r}
dt %>% .$manufacturer %>% fct_unique()

levels(dt$manufacturer)
```

# factor combine and order

## fct_c()

combine factors with different levels

```{r}
dt <- mpg %>% mutate_at(.vars = c("manufacturer", "model", "trans", "class"), .funs = as_factor)

`list of manu` <- levels(dt$manufacturer)

f1 <- `list of manu`[1:7] %>% as.factor()
f2 <- `list of manu`[8:15] %>% as.factor()

fct_c(f1, f2)
```

## fct_relevel()

reordering factor level

```{r}
reorder <- sample(dt$manufacturer %>% fct_unique, size = length(dt$manufacturer %>% fct_unique()), replace = F) %>% as.character()

dt %>% mutate(manufacturer = fct_relevel(manufacturer, reorder)) %>% 
        count(manufacturer)

levels(dt$manufacturer)
```

## fct_infreq()

reorder levels by the frequency in which they appear in the data (highest freq.first)

```{r}
dt %>% mutate(manufacturer = fct_infreq(manufacturer)) %>%
        count(manufacturer)
```

## fct_inorder()

reorder levels by order in which they appear in the data

```{r}
dt %>% mutate(manufacturer = fct_inorder(manufacturer)) %>%
        count(manufacturer)
```

## fct_rev()

reverse level order

```{r}
levels(dt$manufacturer)
levels(fct_rev(dt$manufacturer))

levels(fct_rev(fct_infreq(dt$manufacturer)))
```

# factor value change and add or drop levels

## fct_recode()

manually change level
```{r}
dt %>% mutate(manufacturer = fct_recode(manufacturer,
                                        Oh = 'audi',
                                        yes = "chevrolet")) %>% 
        count(manufacturer)
```

## fct_collapse()

collapse levels into manually defined groups
```{r}
dt %>% mutate(manufacturer = fct_collapse(manufacturer,
                                          `audi & ford` = c("audi", "ford"))) %>% count(manufacturer)
```

## fct_other()

replace levels with other
```{r}
dt %>% mutate(manufacturer = fct_other(manufacturer, c("audi",
                                                       "chevrolet",
                                                       "ford",
                                                       "dodge"))) %>% 
        count(manufacturer)

dt %>% mutate(manufacturer = fct_other(manufacturer, drop = c("audi",
                                                       "chevrolet",
                                                       "ford",
                                                       "dodge"))) %>% 
        count(manufacturer)
```

## fct_expand()

add levels to a factor
```{r}
dt_expanded <- dt %>% mutate(manufacturer = fct_expand(manufacturer, c("NMAX", "XMAX", "VARIO")))

dt_expanded %>% pull(manufacturer) %>% fct_count()
```


## fct_drop()

drop unused levels
```{r}
dt_expanded %>% mutate(manufacturer = fct_drop(manufacturer, c("XMAX"))) %>% pull(manufacturer) %>% fct_count()

dt_expanded %>% mutate(manufacturer = fct_drop(manufacturer, c("XMAX", "NMAX", "VARIO"))) %>% pull(manufacturer) %>% fct_count()
```

## fct_explicit_na

assigns a level to NAs to ensure they appear in plots


# EXERCISE

## Exercise 1
First import corpus.txt into R. Use function readLines() for import, assign imported corpus
to R object.\
```{r}
data <- read_lines("./corpus/corpus.txt")
```
First some warming up:\
 check number of lines in corpus\
 check number of characters\
 print first and last six lines\
```{r}
# number of lines
length(data)
```

```{r}
# number of characters
str_length(data) %>% tibble() %>% sum(.)
```

```{r}
# top 6 and last 6 lines
head(data)
tail(data)
```

Now use regular expressions and tools provided by stringr library to finish given tasks:\
 count how many lines include at least one punctuation\
```{r}
data %>% str_detect(pattern = "[:punct:]") %>% sum()
```

 show first 20 lines without any punctuation\
```{r}
data %>% str_detect(pattern = "[:punct:]", negate = T) %>% sum()

data[data %>% str_detect(pattern = "[:punct:]", negate = T)] %>% head()
data %>% str_subset("[:punct:]", negate = T) %>% head()
```

 count how many lines include at least one number / digit\
```{r}
data %>% str_detect("[:digit:]") %>% sum()
```

 inspect first 10 lines with digit present\
```{r}
data[data %>% str_detect("[:digit:]")] %>% head(10)
```

 find string patterns that resemble phone numbers (search for patterns: ddd-dddd where
d = digit 0-9)\
```{r}
data %>% str_detect("(\\d{3})[-](\\d{4})") %>% sum()

data[data %>% str_detect("(\\d{3})[-](\\d{4})")] %>% head()
data %>% str_subset("(\\d{3})[-](\\d{4})") %>% str_view_all("(\\d{3})[-](\\d{4})")
```

 find string patterns that resemble dollar signs ”$” (escaping needed)\
```{r}
data %>% str_detect("\\$") %>% sum()

data %>% str_subset("\\$") %>% head() %>% str_view_all("\\$")
```

 how many lines starts with word ”The”?\
```{r}
data %>% str_detect("^[Tt]he") %>% sum()
data[data %>% str_detect("^[Tt]he")] %>% head()
```

## Exercise 2

Continue with strings manipulations:\
 use corpus and try to figure out which words usually come before comma ”,”
```{r}
data %>% str_subset("\\w+,") %>% head

data %>% 
        str_extract("\\w+,") %>%
        str_to_lower() %>% 
        str_remove(",") %>%
        tibble(kata = .) %>% 
        count(kata) %>% 
        arrange(desc(n))

# the same approach
data %>% 
        str_extract("\\w{1,},") %>%
        str_to_lower() %>% 
        str_remove(",") %>%
        tibble(kata = .) %>% 
        count(kata) %>% 
        arrange(desc(n))
```

 if you consider first 5 letters at the beginning of each line, what are the top patterns that
lines start with?
```{r}
data %>% str_starts("\\w{1,6} ") %>% head()
data[data %>% str_starts("\\w{1,6} ")] %>% head()

data %>% str_starts("[:alpha:]{5}") %>% head()

data[data %>% str_starts("[:alpha:]{5} ")] %>% head() %>% str_view("[:alpha:]{5} ")
data[data %>% str_starts("^[:alpha:]{5} ")] %>% head() %>% str_view_all("^[:alpha:]{5} ")

data %>% 
        str_extract("^(\\w{5} )") %>%
        str_to_lower() %>% 
        str_remove(" ") %>% 
        tibble(awalan = .) %>% 
        count(awalan) %>% 
        arrange(desc(n))

data %>% 
        str_extract("^(\\w{1,} )") %>%
        str_to_lower() %>%
        str_remove(" ") %>%
        tibble(awalan = .) %>% 
        count(awalan) %>% 
        arrange(desc(n))

data %>% 
        str_sub(1,5) %>% 
        str_to_lower() %>% 
        tibble(pola = .) %>%
        count(pola, sort = T)
```

 find words where: a vowel is followed by a vowel
```{r}
data %>% str_subset("[aiueo]{2}") %>% head() %>% str_view_all("[aiueo]{2}")

data %>% 
        str_extract("\\w+[aiueo]{2}\\w+") %>%
        str_to_lower() %>% 
        tibble(vowel = .) %>% 
        count(vowel, sort = T) %>% 
        tibble()
```

 find words where: a vowel is followed by two or more vowels
```{r}
# find the lines
data %>% 
        str_subset("\\w+[aiueo]{3,}\\w+") %>% 
        head(15) %>% 
        str_view_all("\\w+[aiueo]{3,}\\w+")

# fint the words
tes <- data %>% 
        str_extract("\\w+[aiueo]{3,}\\w+") %>%
        str_to_lower() %>% 
        tibble(pola = .)

tes[!is.na(tes$pola),] %>% count(pola, sort = T)

# find why louis most occurance
data %>% str_to_lower() %>% str_subset("louis") %>% str_view_all("louis")
```

 find words where: 2 vowels are not followed by a vowel
```{r}
# make a view to see the correctness of the syntax
data %>% 
        str_subset(" \\w*[aiueo]{2}[^(aiueo)]* ") %>%
        head(15) %>% 
        str_view_all(" \\w*[aiueo]{2}[^(aiueo)]* ")

data %>% 
        str_extract_all(" \\w*[aiueo]{2}[^(aiueo)]* ") %>%
        unlist() %>% 
        str_to_lower() %>%
        str_replace(" ", "") %>% 
        str_remove_all(" .*") %>% 
        tibble(pola = .) %>% 
        count(pola, sort = T)
```

 check occurrence of words ”the”, ”be”, ”to”, ”of”, ”and” (most common words counts)
```{r}
data %>% 
        str_extract_all("the|be|to|of|and") %>%
        unlist() %>% 
        str_to_lower() %>% 
        tibble(pola = .) %>% 
        count(pola, sort = T)

# onother way
data %>% str_count("and") %>% sum()

hitung <- function(kata){
        return(data %>% str_count(pattern = kata) %>% sum())
        }

hitung("and|the|to|be|of")
```

 most common words counts: sort words by their frequency!
```{r}
data %>% 
        str_extract_all("\\b[A-Za-z]+\\b") %>%
        unlist() %>% 
        str_to_lower() %>% 
        unlist() %>% 
        tibble(kata = .) %>% 
        count(kata, sort = T)
```

 most common words counts: before pattern match convert corpus to lower case!
```{r}
data %>% 
        str_extract_all("\\b[A-Za-z]+\\b") %>%
        unlist() %>% 
        str_to_lower() %>% 
        unlist() %>% 
        tibble(kata = .) %>% 
        count(kata, sort = T)
```

 inside most common words counts find top 3 most common words
```{r}
data %>% 
        str_extract_all("\\b[A-Za-z]+\\b") %>%
        unlist() %>% 
        str_to_lower() %>% 
        unlist() %>% 
        tibble(kata = .) %>% 
        count(kata, sort = T) %>% 
        head(3)
```

 top 3 most common words check: number of lines only one word is present
```{r}
top3 <- data %>% 
        str_extract_all("\\b[A-Za-z]+\\b") %>%
        unlist() %>% 
        str_to_lower() %>% 
        unlist() %>% 
        tibble(kata = .) %>% 
        count(kata, sort = T) %>% 
        head(3)

top3[,1] %>% unlist(use.names = F)

data.low
```

 top 3 most common words check: number of lines 2 words are present
 top 3 most common words check: number of lines all three words are present
 top 3 most common words check: also add percentage % of lines for each given scenario!









